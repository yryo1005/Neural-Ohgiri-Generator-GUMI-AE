{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoEncoderの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像のサイズ\n",
    "IMAGE_HEIGHT = IMAGE_WIDTH = 256\n",
    "\n",
    "# 画像の特徴量次元数\n",
    "IMAGE_FEATURE_DIM = 16384\n",
    "\n",
    "# バッチサイズ\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_preprocess( _image_path ):\n",
    "    _image = tf.io.read_file( _image_path )\n",
    "    _image = tf.image.decode_image( _image, channels = 3, expand_animations = False )\n",
    "    _image = tf.image.resize( _image, (IMAGE_HEIGHT, IMAGE_WIDTH) )\n",
    "    _image = tf.cast( _image, tf.float32 )\n",
    "    _image = _image / 255.0\n",
    "\n",
    "    return _image, _image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bokete_image_annotations.csv\", \"r\", encoding = \"utf-8\") as f:\n",
    "    a = f.readlines()\n",
    "\n",
    "bad_images = set([int(A.strip(\"\\n\").strip(\"\\ufeff\")) for A in a])\n",
    "last_annotation_number = max(bad_images)\n",
    "\n",
    "#\n",
    "len(bad_images), last_annotation_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = image_paths = [\"bokete_image/\" + IP for IP in os.listdir(\"bokete_image\")]\n",
    "\n",
    "tmp = []\n",
    "for IP in image_paths:\n",
    "    image_number = int(IP.split(\"/\")[-1].split(\".\")[0])\n",
    "    if image_number in bad_images or image_number > last_annotation_number: continue\n",
    "    tmp.append(IP)\n",
    "image_paths = tmp\n",
    "\n",
    "#\n",
    "len(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "def generate_dataset( _image_paths ):\n",
    "    _ds = tf.data.Dataset.from_tensor_slices( (image_paths) )\n",
    "    _ds = _ds.map( read_and_preprocess, num_parallel_calls = AUTOTUNE )\n",
    "    _ds = _ds.prefetch( AUTOTUNE )\n",
    "\n",
    "    return _ds\n",
    "\n",
    "train_image_paths, test_image_paths = train_test_split(image_paths, test_size = 0.01)\n",
    "train_dataset = generate_dataset(train_image_paths)\n",
    "test_dataset = generate_dataset(test_image_paths)\n",
    "\n",
    "#\n",
    "len(train_image_paths), len(test_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder():\n",
    "    input = layers.Input(shape = (IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n",
    "    x = layers.Conv2D(filters = 32, kernel_size = 3, strides = 2, padding = \"same\")(input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Conv2D(filters = 64, kernel_size = 3, strides = 2, padding = \"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Conv2D(filters = 128, kernel_size = 3, strides = 2, padding = \"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Conv2D(filters = 256, kernel_size = 3, strides = 2, padding = \"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Conv2D(filters = 512, kernel_size = 3, strides = 2, padding = \"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(units = IMAGE_FEATURE_DIM)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    output = layers.LeakyReLU()(x)\n",
    "    \n",
    "    return models.Model(input, output, name = \"encoder\")\n",
    "\n",
    "def build_decoder():\n",
    "    input = layers.Input(shape = (IMAGE_FEATURE_DIM, ))\n",
    "    x = layers.Dense(units = np.prod((8, 8, 512)) )(input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.Reshape(target_shape = (8, 8, 512))(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(filters = 256, kernel_size = 3, strides = 2, padding = \"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(filters = 128, kernel_size = 3, strides = 2, padding = \"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(filters = 64, kernel_size = 3, strides = 2, padding = \"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(filters = 32, kernel_size = 3, strides = 2, padding = \"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(filters = 16, kernel_size = 3, strides = 2, padding = \"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Conv2D(filters = 3, kernel_size = 3, strides = 1, padding = \"same\")(x)\n",
    "    output = layers.Activation(\"sigmoid\")(x)\n",
    "\n",
    "    return models.Model(input, output, name = \"decoder\")\n",
    "\n",
    "def build_autoencoder(encoder, decoder):\n",
    "    input = layers.Input(shape = (IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n",
    "    x = encoder(input)\n",
    "    output = decoder(x)\n",
    "\n",
    "    return models.Model(input, output, name = \"autoencoder\")\n",
    "\n",
    "encoder = build_encoder()\n",
    "decoder = build_decoder()\n",
    "autoencoder = build_autoencoder(encoder, decoder)\n",
    "\n",
    "#\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowProgress(callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs = None):\n",
    "        i = np.random.randint(len(test_image_paths))\n",
    "        image = read_and_preprocess(test_image_paths[i])[0]\n",
    "\n",
    "        pred = self.model.predict(np.reshape(image, (1, IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\n",
    "        pred = np.reshape(pred, (IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n",
    "\n",
    "        fig = plt.figure(figsize = (10, 20))\n",
    "        ax = fig.add_subplot(1, 2, 1)\n",
    "        ax.imshow(image)\n",
    "        ax.set_title(\"input\")\n",
    "\n",
    "        ax = fig.add_subplot(1, 2, 2)\n",
    "        ax.imshow(pred)\n",
    "        ax.set_title(\"pred\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "check_point = callbacks.ModelCheckpoint(filepath = './autoencoder.h5', \n",
    "                                        monitor = 'val_loss', verbose = 1,\n",
    "                                        save_best_only = True, save_weights_only = False,\n",
    "                                        mode='min', period=1)\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience = 5, verbose = 1, mode = 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(lr = 0.0001)\n",
    "loss = losses.MeanSquaredError()\n",
    "\n",
    "autoencoder.compile(loss = loss, optimizer = optimizer)\n",
    "autoencoder.fit(train_dataset.batch(BATCH_SIZE), epochs = 150, validation_data = test_dataset.batch(BATCH_SIZE), \n",
    "                callbacks = [ShowProgress(), check_point, early_stopping])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_nogpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b3bb25648a9c884d40b682873456bcab670fb8ca36f33f6d58979330ee7fdcc2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
